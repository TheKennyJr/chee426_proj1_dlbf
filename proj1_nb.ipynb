{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHEE 426 Project 1\n",
    "Spring 2024\n",
    "\n",
    "This is a demonstration of how to work on the Project 1. Use this notebook as a guide or template.\n",
    "\n",
    "This is based on the textbook notebook for Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Problem Statement:\n",
    "\n",
    "This Project 1 for the course is the application of the concepts and techniques for the materials covered in Chapter 1 and 2. The problem you have to solve is to develop a regression model for the prediction of CO emissions of light-duty vehicles by training on the fuel economy dataset collected by US-EPA for vehicle model year 2024. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Modules (packages) \n",
    "Packages are where we will get functions to use in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the Kernel you are using is the environment you created for this project.\n",
    "# Any imports of Pyhton modules may result to error if your Kernel is not your intended environment\n",
    "#\n",
    "# The current Kernel is shown i the Upper-right corner of this notebook.\n",
    "# To change Kernel: Menu > Kernel > Change Kernel... > click drop-down and select the name of the environment you created for the project\n",
    "# The default Kernel in a Jupyter Notebook is the base(root) Python\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the the CSV file of the data 'proj1data.csv' is in the same folder as this notebook file.\n",
    "\n",
    "df = pd.read_csv('proj1data.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chekc column names: note that each dataset has its own set column names so check the colnames verytime\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Stumbling block a bit here (above).\n",
    "# The column names are not good for Pyhotn code due to the special characters. More challenging than the author textbook demo.\n",
    "#\n",
    "# We have to remove some unwanted characters in addiiton ot 'white space' such as: (, ), /, **\n",
    "#\n",
    "# We can do this using Pandas function str.replace() with the argument: ('[^\\w]','', regex=True)\n",
    "# That is, replace everything other than \\w . \\w Matches alphanumeric characters and the underscore, _.\n",
    "#\n",
    "# If you wonder how to know what to do in cases like this challenging one. Google it! No kidding. There is a wide\n",
    "# community of Python coders doing ML all around the world. There are online forums where issues/challenges and solutions\n",
    "# are being exhanged. This is still way better than ChatGPT (at least for now). \n",
    "# Or, if you are very patient, check the documentation of Pandas\n",
    "#\n",
    "################################################\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(' ','_', regex=True) # replace all spaces with '_'\n",
    "df.columns = df.columns.str.lower().str.replace('[^\\w]','', regex=True) # then remove all spacial characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chekc column names to verify no unwanted characters in colnames\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at the distribution of values in the targte output Y whihc is CO\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "sns.histplot(df.co_gmi, bins=40, color='black', alpha=1)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('CO(g/mi)')\n",
    "plt.title('Distribution of CO(g/mi)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the distribution at the lower values of CO\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "sns.histplot(df.co_gmi[df.co_gmi < 2], bins=40, color='black', alpha=1)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('CO(g/mi)')\n",
    "plt.title('Distribution of CO(g/mi)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_co = np.log1p(df.co_gmi)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "sns.histplot(log_co, bins=40, color='black', alpha=1)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Log(CO + 1)')\n",
    "plt.title('Distribution of CO levels after log tranformation')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Based on the graph below, log-transformation does not signficantly change the look of CO distribution, \n",
    "# so log-transform on CO will not have significant improvement effect on the eventual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NULL or NA, or NaN values in each column in the dataset \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random number seed for reproducility of results by other users of the notebook\n",
    "np.random.seed(2)\n",
    "\n",
    "\n",
    "# Since the target var CO cannot have NULL values, let's remove the rows (data-points) that have CO=NULL or NaN or NA\n",
    "# We have to do this before we perform the succeeding steps of splitting the dataset\n",
    "\n",
    "df = df.dropna(subset = ['co_gmi'])\n",
    "\n",
    "# Now splitting the dataset using 20% for Test set and the remianing 80% for Train+Val set\n",
    "n = len(df)\n",
    "\n",
    "n_val = int(0.2 * n)\n",
    "n_test = int(0.2 * n)\n",
    "n_train = n - (n_val + n_test)\n",
    "\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "df_shuffled = df.iloc[idx]\n",
    "\n",
    "df_train = df_shuffled.iloc[:n_train].copy()\n",
    "df_val = df_shuffled.iloc[n_train:n_train+n_val].copy()\n",
    "df_test = df_shuffled.iloc[n_train+n_val:].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential Questions at this stage for Exam 1:\n",
    "1. How many data samples are there in the Test set?\n",
    "2. How many data samples are there in the Train set?\n",
    "3. How many data samples are there in the Validation set?\n",
    "\n",
    "Use Python function to compute the answers to the questions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The target Y for your Poject 1 is CO (g/mi)\n",
    "\n",
    "y_train_orig = df_train.co_gmi.values\n",
    "y_val_orig = df_val.co_gmi.values\n",
    "y_test_orig = df_test.co_gmi.values\n",
    "\n",
    "# no need for log-transform as shown above, so we just equate the vars\n",
    "y_train = y_train_orig\n",
    "y_val = y_val_orig\n",
    "y_test = y_test_orig\n",
    "\n",
    "# since CO is a Y variable, then delete it from the pool of potential X variables\n",
    "del df_train['co_gmi']\n",
    "del df_val['co_gmi']\n",
    "del df_test['co_gmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the linear regression algorithm (closed-form formula to compute the linear model coefficients)\n",
    "\n",
    "def train_linear_regression(X, y):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    return w[0], w[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you select your predicror variables or X variables.\n",
    "# Remember your project constraint: use at least 10 X varibales (except CO(g/mi) or course), and at least 1 X-var is a categorical var\n",
    "# How to know which X-var to select? Check the PDF document of Variable Definition, which is also uploaded in Moodle under Project 1\n",
    "#\n",
    "\n",
    "base = ['test_veh_displacement_l', # this is the engine cylinder displacement\n",
    "        'rated_horsepower', # thisis the horsepower rating\n",
    "        'axle_ratio', # thi sis the axle ratio\n",
    "        'nv_ratio', # this is the N/V ratio\n",
    "        #'vehicle_type' # this is the Categorical variable Vehicle type, but let us exclude it for now in the baseline model (only numeric X vars)\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare1_X(df):\n",
    "    df_num = df[base]\n",
    "    df_num = df_num.fillna(0)\n",
    "    X = df_num.values\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare1_X(df_train)\n",
    "w_0, w = train_linear_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = w_0 + X_train.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "sns.histplot(y_train, label='target', color='#222222', alpha=0.6, bins=40)\n",
    "sns.histplot(y_pred, label='prediction', color='#aaaaaa', alpha=0.8, bins=40)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Log(Price + 1)')\n",
    "plt.title('Predictions vs actual distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    error = y_pred - y\n",
    "    mse = (error ** 2).mean()\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = prepare1_X(df_val)\n",
    "y_pred = w_0 + X_val.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple feature engineering\n",
    "Let use now include the 1 Categorical variable into the model as an X var.\n",
    "I chose for this demo the variable VEHICLE TYPE with column name 'vehicle_type'. This is a categorical data, so we have to convert this to numeric data.\n",
    "To convert to numeric, we use the \"One-Hot Encoding\" technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_type'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see above that 'vehicle_type' has 3 levels or categories: Truck, Car, Both.\n",
    "Let us use these levels for One-Hot Encoding.\n",
    "\n",
    "Also, I will give a different name to this preparation function so it is not confused with baseline prepare1_X() function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare2_X(df):\n",
    "    df = df.copy()\n",
    "    features = base.copy()\n",
    "\n",
    "    for v in ['Truck', 'Car', 'Both']:\n",
    "        feature = 'is_type_%s' % v\n",
    "        df[feature] = (df['vehicle_type'] == v).astype(int)\n",
    "        features.append(feature)\n",
    "\n",
    "    df_num = df[features]\n",
    "    df_num = df_num.fillna(0)\n",
    "    X = df_num.values\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running preparation\n",
    "X_train = prepare2_X(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chekcing if the one-hot encoding really worked\n",
    "# note: X_train is now a numpy array. The prepare2_X() function has 'X = df_num.values', \n",
    "# which outputs only the values and no column names attached. \n",
    "# The added on-hot coding columns are at the end of the numpy array.\n",
    "# Notice the numbers, 1 and 0, as indicators of presence and absence of the feature\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that there are now seven X vars: 'test_veh_displacement_l', \n",
    "#                                            'rated_horsepower',\n",
    "#                                            'axle_ratio', \n",
    "#                                            'nv_ratio',\n",
    "#                                            'is_type_Trucks',\n",
    "#                                            'is_type_Cars',\n",
    "#                                            'is_type_Boths',\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Another Linear Regression Model \n",
    "Now including the VEHICLE TYPE variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w_0, w = train_linear_regression(X_train, y_train)\n",
    "\n",
    "y_pred = w_0 + X_train.dot(w)\n",
    "print('train:', rmse(y_train, y_pred))\n",
    "\n",
    "X_val = prepare2_X(df_val)\n",
    "y_pred = w_0 + X_val.dot(w)\n",
    "print('validation:', rmse(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo Remarks\n",
    "So, this is an illustration of how to adapt a template Jupyter Notebook to a new project and new dataset.\n",
    "\n",
    "This is what you do in your Porject 1. And of course you can use this notebook as your template.\n",
    "\n",
    "Make sure to continue in the next steps to include Regulatization in the model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression_reg(X, y, r=0.0):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    XTX = X.T.dot(X)\n",
    "    reg = r * np.eye(XTX.shape[0])\n",
    "    XTX = XTX + reg\n",
    "\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    return w[0], w[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare2_X(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in [0, 0.001, 0.01, 0.1, 1, 10]:\n",
    "    w_0, w = train_linear_regression_reg(X_train, y_train, r=r)\n",
    "    print('%5s, %.2f, %.2f, %.2f' % (r, w_0, w[1], w[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare2_X(df_train)\n",
    "w_0, w = train_linear_regression_reg(X_train, y_train, r=0)\n",
    "\n",
    "y_pred = w_0 + X_train.dot(w)\n",
    "print('train', rmse(y_train, y_pred))\n",
    "\n",
    "X_val = prepare2_X(df_val)\n",
    "y_pred = w_0 + X_val.dot(w)\n",
    "print('val', rmse(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare2_X(df_train)\n",
    "w_0, w = train_linear_regression_reg(X_train, y_train, r=0.01)\n",
    "\n",
    "y_pred = w_0 + X_train.dot(w)\n",
    "print('train', rmse(y_train, y_pred))\n",
    "\n",
    "X_val = prepare2_X(df_val)\n",
    "y_pred = w_0 + X_val.dot(w)\n",
    "print('val', rmse(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare2_X(df_train)\n",
    "X_val = prepare2_X(df_val)\n",
    "\n",
    "for r in [0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]:\n",
    "    w_0, w = train_linear_regression_reg(X_train, y_train, r=r)\n",
    "    y_pred = w_0 + X_val.dot(w)\n",
    "    print('%6s' %r, rmse(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare2_X(df_train)\n",
    "w_0, w = train_linear_regression_reg(X_train, y_train, r=0.01)\n",
    "\n",
    "X_val = prepare2_X(df_val)\n",
    "y_pred = w_0 + X_val.dot(w)\n",
    "print('validation:', rmse(y_val, y_pred))\n",
    "\n",
    "X_test = prepare2_X(df_test)\n",
    "y_pred = w_0 + X_test.dot(w)\n",
    "print('test:', rmse(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us select a vehicle in the Test set to predict its CO emission\n",
    "# with index=2, this is a 2024, Mercedes-Benz, Model: CLA 250 4MATIC\n",
    "\n",
    "i = 2\n",
    "ad = df_test.iloc[i].to_dict()\n",
    "ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = prepare2_X(pd.DataFrame([ad]))[0]\n",
    "y_pred = w_0 + X_test.dot(w)\n",
    "co_gmi_predicted = np.expm1(y_pred)\n",
    "co_gmi_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the value of the observed CO(g/mi) in data sample i=2 in Y-test set\n",
    "co_gmi_observed = y_test[i]\n",
    "co_gmi_observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Remarks\n",
    "\n",
    "These final results,co_gmi_predicted and co_gmi_observed, must now be assessed by an Environmental Engineer via domain-knowledge to decide if the model is accurate enough in its predictions.\n",
    "\n",
    "Of course, you can go back up and try to improve your model:\n",
    "1. What if you use a different set of X-variables?\n",
    "2. What if a data transformation such as log-transformation is implememented on the data X and/or Y vars?\n",
    "3. What if you group the main dataset according to certain obvious factor such as test-Fuel type?\n",
    "4. And many more...usually with the input of other experts. Some publications about the subject might also help you on how to improve your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:chee426] *",
   "language": "python",
   "name": "conda-env-chee426-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
